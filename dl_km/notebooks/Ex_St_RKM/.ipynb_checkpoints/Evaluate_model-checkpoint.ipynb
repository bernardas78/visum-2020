{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages and download pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import scipy.misc\n",
    "import torch\n",
    "import argparse\n",
    "import stiefel_rkm_model\n",
    "#from St_RKM_train import Lin_View\n",
    "from tqdm import tqdm\n",
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if not os.path.exists('out/3dshapes/3dshapes_Trained_rkm.tar'):\n",
    "        print('Pre-trained model at given path doesn\\'t exist. Downloading now...')\n",
    "        os.system(\"  wget -O out/3dshapes/3dshapes_Trained_rkm.tar https://www.dropbox.com/s/chwzwaodljq2bn9/3dshapes_Trained_rkm.tar?dl=1\")\n",
    "        print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enter path to load the pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maverick/.conda/envs/py_env/lib/python3.6/site-packages/torch/serialization.py:593: SourceChangeWarning: source code of class 'stiefel_rkm_model.RKM_Stiefel' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/maverick/.conda/envs/py_env/lib/python3.6/site-packages/torch/serialization.py:593: SourceChangeWarning: source code of class 'stiefel_rkm_model.Net1' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/maverick/.conda/envs/py_env/lib/python3.6/site-packages/torch/serialization.py:593: SourceChangeWarning: source code of class 'stiefel_rkm_model.Net3' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/maverick/.conda/envs/py_env/lib/python3.6/site-packages/torch/serialization.py:593: SourceChangeWarning: source code of class 'stiefel_rkm_model.Lin_View' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'get_dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e283e2e40ed2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNamespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mxtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnChannels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mWH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Number of channels in image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "parser.add_argument('--filename', type=str, default='3dshapes_Trained_rkm', help='Enter Filename')\n",
    "parser.add_argument('--dataset_name', default='3dshapes', type=str, help='Enter dataset name')\n",
    "opt_gen = parser.parse_args(args=[])\n",
    "\n",
    "sd_mdl = torch.load('out/{}/{}.tar'.format(opt_gen.dataset_name, opt_gen.filename),\n",
    "                    map_location=lambda storage, loc: storage)\n",
    "\n",
    "rkm = sd_mdl['rkm']\n",
    "rkm.load_state_dict(sd_mdl['rkm_state_dict'])\n",
    "h = sd_mdl['h']\n",
    "U = sd_mdl['U']\n",
    "opt = sd_mdl['opt']\n",
    "\n",
    "\"\"\" Load Data \"\"\"\n",
    "opt.mb_size = 500\n",
    "opt.workers = 16\n",
    "opt.shuffle = True\n",
    "opt = argparse.Namespace(**vars(opt), **vars(opt_gen))\n",
    "xtrain, _, nChannels = get_3dshapes_dataloader(args=opt)\n",
    "\n",
    "WH = next(iter(xtrain))[0].shape[2]  # Number of channels in image\n",
    "\n",
    "ct = time.strftime(\"%Y%m%d-%H%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # Visualize correlatedness of latent variables\n",
    "    cov = torch.mm(torch.t(h), h)\n",
    "    print('Cov(H):\\n {}'.format(cov))\n",
    "    plt.figure()\n",
    "    plt.imshow(cov.detach().cpu().numpy())\n",
    "    plt.title('Cov(H)')\n",
    "    plt.show()\n",
    "    \n",
    "    # # Visualize quality of reconstructed samples\n",
    "    perm1 = torch.randperm(len(xtrain.dataset))\n",
    "    m = 5\n",
    "    fig2, ax = plt.subplots(m, m)\n",
    "    it = 0\n",
    "    for i in range(m):\n",
    "        for j in range(m):\n",
    "            ax[i, j].imshow(utils.convert_to_imshow_format(xtrain.dataset[perm1[it]][0].numpy()))\n",
    "            it += 1\n",
    "    plt.suptitle('Ground Truth')\n",
    "    plt.setp(ax, xticks=[], yticks=[])\n",
    "    plt.show()\n",
    "\n",
    "    fig1, ax = plt.subplots(m, m)\n",
    "    x_gen = rkm.decoder(torch.mm(h[perm1[:m * m], :], U.t()).float()).detach().numpy().reshape(-1, nChannels, WH, WH)\n",
    "    it = 0\n",
    "    for i in range(m):\n",
    "        for j in range(m):\n",
    "            ax[i, j].imshow(utils.convert_to_imshow_format(x_gen[it, :, :, :]))\n",
    "            it += 1\n",
    "    plt.suptitle('Reconstructed samples')\n",
    "    plt.setp(ax, xticks=[], yticks=[])\n",
    "    plt.show()\n",
    "\n",
    "    # Scatter plot of latent variables with histogram ===================\n",
    "    # utils.scatter_w_hist(h)\n",
    "\n",
    "    # Interpolation along principal components ================\n",
    "    for i in range(opt.h_dim):\n",
    "        dim = i\n",
    "        m = 35  # Number of steps\n",
    "        mul_off = 0.5  # (for no-offset, set multiplier to 0)\n",
    "\n",
    "        # Manually set the linspace range or get from Unit-Gaussian\n",
    "        lambd = torch.linspace(-2, 2, steps=m)\n",
    "        # lambd = torch.linspace(*utils._get_traversal_range(0.475), steps=m)\n",
    "\n",
    "        uvec = torch.FloatTensor(torch.zeros(h.shape[1]))\n",
    "        uvec[dim] = 1  # unit vector\n",
    "        yoff = mul_off * torch.ones(h.shape[1]).float()\n",
    "        yoff[dim] = 0\n",
    "\n",
    "        yop = yoff.repeat(lambd.size(0), 1) + torch.mm(torch.diag(lambd),\n",
    "                                                       uvec.repeat(lambd.size(0), 1))  # Traversal vectors\n",
    "        x_gen = rkm.decoder(torch.mm(yop, U.t()).float()).detach().numpy().reshape(-1, nChannels, WH, WH)\n",
    "\n",
    "        # Save Images in the directory\n",
    "        if not os.path.exists('Traversal_imgs/{}/{}/{}'.format(opt.dataset_name, opt.filename, dim)):\n",
    "            os.makedirs('Traversal_imgs/{}/{}/{}'.format(opt.dataset_name, opt.filename, dim))\n",
    "\n",
    "        for j in range(x_gen.shape[0]):\n",
    "            scipy.misc.imsave(\n",
    "                'Traversal_imgs/{}/{}/{}/{}im{}.png'.format(opt.dataset_name, opt.filename, dim, dim, j),\n",
    "                utils.convert_to_imshow_format(x_gen[j, :, :, :]))\n",
    "\n",
    "    print('Traversal Images saved in: Traversal_imgs/{}/{}/'.format(opt.dataset_name, opt.filename))\n",
    "\n",
    "    # Random samples from dist. over H ============================================================\n",
    "    utils.gen_gt_imgs(dataset_name=opt.dataset_name, xtrain=xtrain)  # Generate Ground-truth images\n",
    "    for i in tqdm(range(10)):  # Fit a Gaussian and generate random-images\n",
    "        if not os.path.exists('Rand_gen_imgs/{}/{}/{}/{}'.format(opt.dataset_name, opt.filename, ct, i)):\n",
    "            os.makedirs('Rand_gen_imgs/{}/{}/{}/{}'.format(opt.dataset_name, opt.filename, ct, i))\n",
    "    \n",
    "        print('Generating random images')\n",
    "        n_samples = 8000\n",
    "        gmm = GMM(n_components=1, covariance_type='full').fit(h.detach().cpu().numpy())\n",
    "        z = torch.FloatTensor(gmm.sample(n_samples)[0])\n",
    "    \n",
    "        x_gen = rkm.decoder(torch.mm(z, U.t())).detach().cpu().numpy().reshape(-1, nChannels, WH, WH)\n",
    "    \n",
    "        for iter in range(n_samples):\n",
    "            scipy.misc.imsave(\n",
    "                'Rand_gen_imgs/{}/{}/{}/{}/Rand_samp_im{}_{}.png'\n",
    "                    .format(opt.dataset_name, opt.filename, ct, i, iter, time.strftime(\"%Y%m%d-%H%M\")),\n",
    "                utils.convert_to_imshow_format(x_gen[iter, :, :, :]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
