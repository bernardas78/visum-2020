{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Mover's Distance\n",
    "\n",
    "In this notebook, we will see an application of Optimal Transport to the problem of computing similarities between sentences and texts. The method under the lens is called 'Word Mover's Distance' about 'Earth Mover's Distance', another name of the Wasserstein $1$ distance, mostly used in computer vision. \n",
    "\n",
    "Traditionally, portions of texts are compared by Cosine similarity on bag-of-words vectors, i.e. histograms of occurrences of words in a text. It captures the exact similarity in terms of words, but two very related sentences can be orthogonal if the words that are used have the same semantic but are different. Such a semantic distance can be obtained by using *word embeddings*, that are embeddings of words in a Euclidean space (of potentially large dimension) where the Euclidean distance has a semantic meaning: two related words will be close in such embeddings. A popular embedding is the *word2vec* embedding, obtained with neural networks. A study of those mechanisms is not in the scope of this notebook, but the interested reader can find more information on [the corresponding Wikipedia page](https://en.wikipedia.org/wiki/Word2vec). Throughout the rest of this tutorial, we will use a subset of the [GloVe] (https://nlp.stanford.edu/projects/glove/) embedding.\n",
    "\n",
    "The key observation made by Kusner and colleagues [1] is that when confronted to a sentence/document, the optimal transport distance can be used between histograms of occurring words using a ground metric obtained through word embeddings. In such a way, related words will be matched together, and the resulting distance will somehow express semantic relatedness between the content.\n",
    "\n",
    "[1] Kusner, M., Sun, Y., Kolkin, N., & Weinberger, K. (2015, June). From word embeddings to document distances. In International Conference on Machine Learning (pp. 957-966). http://proceedings.mlr.press/v37/kusnerb15.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A basic example \n",
    "\n",
    "We will start by reproducing Figure $1$ in the original paper:\n",
    "\n",
    "<img src=\"https://remi.flamary.com/cours/otml/fig1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two sentences are considered: 'Obama speaks to the media in Illinois' and 'The president greets the press in Chicago'. It is clear from this example that the Cosine similarity between the two sentences indicates that the two sentences are not related since there is no word in common.  We will start by some imports and creating a list of the two sentences as words without stopwords that are not relevant for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pylab as pl\n",
    "import ot\n",
    "\n",
    "\n",
    "s1 = ['Obama','speaks','media','Illinois']\n",
    "s2 = ['President','greets','press','Chicago']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a subset of the GloVe word embedding, expressed as a dictionary ```(word, embedding)``` that you can load this way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dict   \n",
    "model=dict(np.load('data/model.npz'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the embedded representation of the sentences can be obtained by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_embed = np.array([model[w] for w in s1])\n",
    "s2_embed = np.array([model[w] for w in s2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the multidimensional scaling method in ```sklearn```, try to visualize the corresponding embedding of words in 2D:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import manifold\n",
    "\n",
    "C = ot.dist(np.vstack((s1_embed,s2_embed)))\n",
    "\n",
    "nmds = manifold.MDS(\n",
    "        2,\n",
    "        eps=1e-9,\n",
    "        dissimilarity=\"precomputed\",\n",
    "        n_init=1)\n",
    "npos = nmds.fit_transform(C)\n",
    "\n",
    "pl.figure(figsize=(6,6))\n",
    "pl.scatter(npos[:4,0],npos[:4,1],c='r',s=50, edgecolor = 'k')\n",
    "for i, txt in enumerate(s1):\n",
    "    pl.annotate(txt, (npos[i,0]-4,npos[i,1]+2),fontsize=20)\n",
    "pl.scatter(npos[4:,0],npos[4:,1],c='b',s=50, edgecolor = 'k')\n",
    "for i, txt in enumerate(s2):\n",
    "    pl.annotate(txt, (npos[i+4,0]-4,npos[i+4,1]+2),fontsize=20)\n",
    "pl.axis('off')\n",
    "pl.tight_layout()\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now compute the coupling between those two distributions and visualize the corresponding result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C2= ot.dist(s1_embed,s2_embed)\n",
    "G=ot.emd(ot.unif(4),ot.unif(4),C2)\n",
    "\n",
    "pl.figure(figsize=(6,6))\n",
    "pl.scatter(npos[:4,0],npos[:4,1],c='r',s=50, edgecolor = 'k')\n",
    "for i, txt in enumerate(s1):\n",
    "    pl.annotate(txt, (npos[i,0]-4,npos[i,1]+2),fontsize=20)\n",
    "pl.scatter(npos[4:,0],npos[4:,1],c='b',s=50, edgecolor = 'k')\n",
    "for i, txt in enumerate(s2):\n",
    "    pl.annotate(txt, (npos[i+4,0]-4,npos[i+4,1]+2),fontsize=20)\n",
    "for i in range(G.shape[0]):\n",
    "    for j in range(G.shape[1]):\n",
    "        if G[i,j]>1e-5:\n",
    "            pl.plot([npos[i,0],npos[j+4,0]],[npos[i,1],npos[j+4,1]],'k',alpha=G[i,j]/np.max(G))\n",
    "pl.title('Word embedding and coupling with OT')\n",
    "pl.axis('off')\n",
    "pl.tight_layout()\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence similarity\n",
    "We will now explore the superiority of this Word mover distance (WMD) in a regression context, where our goal is to estimate the similarity (or relatedness) of two sentences on a scale of 0 to 5 (5 being the most similar). Given a set of pairs of sentences with a human-annotated relatedness, our goal is to predict the relatedness from a new pair of sentences.\n",
    "\n",
    "We will use the [SICK (Sentences Involving Compositional Knowledge) dataset](http://clic.cimec.unitn.it/composes/sick.html) for this purpose.\n",
    "\n",
    "We first load it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data=np.load('data/data_text.npz')   \n",
    "setA=data['setA']\n",
    "setB=data['setB']\n",
    "scores=data['scores']\n",
    "\n",
    "# Some important prints\n",
    "print (setA[0])\n",
    "print (setB[0])\n",
    "print(scores[0])\n",
    "\n",
    "# Save data for later usage\n",
    "np.savez('data/data_text.npz',setA=setA,setB=setB,scores=scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will only keep 200 sentences for learning our regression model and the rest for testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=200\n",
    "testA=setA[n:]\n",
    "trainA=setA[:n]\n",
    "testB=setB[n:]\n",
    "trainB=setB[:n]\n",
    "\n",
    "scores_train=scores[:n]\n",
    "scores_test=scores[n:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the countVectorizer model from ```sklearn```, compute all the bag-of-words representations of the sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer(stop_words=\"english\").fit(np.hstack((setA,setB)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a big data matrix of all the words present in the dataset embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_feat = [model[w] for w in vect.get_feature_names()]\n",
    "all_feat = np.array(all_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute a big matrix of all pairwise feature distances using the ```dist()``` method of ```POT```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = ot.dist(all_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can write a code that will compute the Cosine and WMD dissimilarities from all the pairs of the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists to append data\n",
    "X_cos=[]\n",
    "X_wmd=[]\n",
    "Y=[]\n",
    "\n",
    "# Append data to the lists\n",
    "for i in range(len(trainA)):\n",
    "    s1 = vect.transform([trainA[i]]).toarray().ravel()\n",
    "    s2 = vect.transform([trainB[i]]).toarray().ravel()\n",
    "    # cosine similarity between bag of words\n",
    "    d_cos=np.cos(np.dot(s1,s2))\n",
    "    X_cos.append(d_cos)\n",
    "    # WMD\n",
    "    s1=s1.astype(np.float)/np.sum(s1)\n",
    "    s2=s2.astype(np.float)/np.sum(s2)\n",
    "    d_wmd=ot.emd2(s1,s2,D)\n",
    "    X_wmd.append(d_wmd)\n",
    "    Y.append(scores_train[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the corresponding golden similarities/distance from the learning set. Hence you have a first appreciation of how much WMD better captures this similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.figure()\n",
    "pl.scatter(X_cos,Y)\n",
    "pl.title('Cosine Similarity VS golden score')\n",
    "pl.show()\n",
    "pl.figure()\n",
    "pl.scatter(X_wmd,Y)\n",
    "pl.title('WMD Similarity VS golden score')\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can learn a simple regression model between those 2 quantities. Use a polynomial of degree 2 to learn the regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.polynomial.polynomial as poly\n",
    "k_cos = poly.polyfit(X_cos, Y, 2)\n",
    "k_wmd = poly.polyfit(X_wmd, Y, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compute from your regression model the estimated relatedness for all the pairs in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cos=[]\n",
    "X_wmd=[]\n",
    "Y_test=[]\n",
    "for i in range(len(testA)):\n",
    "    s1 = vect.transform([testA[i]]).toarray().ravel()\n",
    "    s2 = vect.transform([testB[i]]).toarray().ravel()\n",
    "    # cosine similarity between bag of words\n",
    "    d_cos=np.cos(np.dot(s1,s2))\n",
    "    X_cos.append(d_cos)\n",
    "    # WMD\n",
    "    s1=s1.astype(np.float)/np.sum(s1)\n",
    "    s2=s2.astype(np.float)/np.sum(s2)\n",
    "    d_wmd=ot.emd2(s1,s2,D)\n",
    "    X_wmd.append(d_wmd)\n",
    "    Y_test.append(scores_test[i])\n",
    "\n",
    "Y_cos = poly.polyval(X_cos, k_cos)\n",
    "Y_wmd = poly.polyval(X_wmd, k_wmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use MSE, Spearman's $\\rho$ and Pearson coefficients to measure the quality of our regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate the quality of your regression model for both Cosine and WMD dissimilarities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-------- Cosine')\n",
    "\n",
    "pr = pearsonr(Y_cos, Y_test)[0]\n",
    "sr = spearmanr(Y_cos,Y_test)[0]\n",
    "se = mse(Y_cos,Y_test)\n",
    "\n",
    "print('Test Pearson (test): ' + str(pr))\n",
    "print('Test Spearman (test): ' + str(sr))\n",
    "print('Test MSE (test): ' + str(se))\n",
    "\n",
    "print('-------- WMD')\n",
    "\n",
    "pr = pearsonr(Y_wmd, Y_test)[0]\n",
    "sr = spearmanr(Y_wmd,Y_test)[0]\n",
    "se = mse(Y_wmd,Y_test)\n",
    "\n",
    "print('Test Pearson (test): ' + str(pr))\n",
    "print('Test Spearman (test): ' + str(sr))\n",
    "print('Test MSE (test): ' + str(se))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad isn't it?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
